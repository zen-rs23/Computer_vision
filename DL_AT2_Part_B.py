# -*- coding: utf-8 -*-
"""DL_AT2_Part_B.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_L1bbQvzd4hr9Npw0FDu1aOIxrVjcCIJ
"""

# Connect to google drive
from google.colab import drive
drive.mount('/content/drive')

import os
import tarfile
import matplotlib.pyplot as plt
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import random
from tqdm import tqdm
from torchvision import transforms, datasets
import torchvision.models as models
from torch.utils.data import DataLoader, random_split
from torch.optim.lr_scheduler import ReduceLROnPlateau
from torch.utils.data import Subset
from PIL import Image
import matplotlib.pyplot as plt
import numpy as np

"""## 2. Data Loading and Preprocessing
Extract the dataset and define transformations.
"""

# Path to the dataset file in Google Drive
file_path = '/content/drive/My Drive/food-101.tar.gz'
# Directory to extract the dataset to
extract_dir = '/content/food101/'

# Create the extraction directory if it doesn't exist
os.makedirs(extract_dir, exist_ok=True)

# Extract the dataset
with tarfile.open(file_path, 'r:gz') as tar:
    tar.extractall(extract_dir)

# List the files in the extraction directory to verify extraction
os.listdir(extract_dir)

# Path to the root folder of the Food101 dataset
data_path = '/content/food101/food-101'

# Load the dataset
class Food101Dataset(torch.utils.data.Dataset):
    def __init__(self, data_path, split='train', transform=None):
        self.data_path = data_path
        self.split = split
        self.transform = transform

        # Read the file names for the specified split
        with open(f'{data_path}/meta/{split}.txt', 'r') as file:
            self.file_names = file.read().splitlines()
        # Create a mapping from class names to integer labels
        self.class_to_idx = {class_name: idx for idx, class_name in enumerate(sorted(os.listdir(f'{data_path}/images')))}
        self.classes = list(self.class_to_idx.keys())
    def __len__(self):
        return len(self.file_names)

    def __getitem__(self, idx):
        img_path = f'{self.data_path}/images/{self.file_names[idx]}.jpg'
        image = Image.open(img_path).convert('RGB')

        if self.transform:
            image = self.transform(image)

        # Extract class label from the file path
        class_name = img_path.split('/')[-2]
        label = self.class_to_idx[class_name]

        return image,class_name,label

image_size = 224

# Define a series of transformations to apply to the training images
transform_train = transforms.Compose([
    transforms.RandomResizedCrop(image_size),  # Randomly crop and resize the image to the specified size
    transforms.RandomHorizontalFlip(p=0.5),  # Randomly flip the image horizontally with a probability of 0.5
    transforms.RandomRotation(15),  # Randomly rotate the image by +/- 15 degrees
    transforms.ToTensor(),  # Convert the image to a PyTorch tensor
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize the image
])

# Define a series of transformations to apply to the testing images
transform_test = transforms.Compose([
    transforms.Resize(size=(image_size, image_size)),  # Resize the image to the specified size
    transforms.CenterCrop(image_size),  # Center crop the image to the size specified
    transforms.ToTensor(),  # Convert the image to a PyTorch tensor
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize the image
])

train_dataset = Food101Dataset(data_path, split='train',transform=transform_train)

# Calculate the size of the validation set (e.g., 20% of the dataset)
val_size = int(0.2 * len(train_dataset))

# Calculate the size of the training set
train_size = len(train_dataset) - val_size

# Split the dataset into training and validation subsets
train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])

test_dataset = Food101Dataset(data_path, split='test', transform=transform_test)

# Data Loaders
batch_size = 32
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True)
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

len(train_loader), len(val_loader), len(test_loader)

# Function to show an image
def imshow(img):
  """Displays an image after necessary transformations."""
  # Assuming your transformations are already applied within train_dataset
  img = img.numpy().transpose((1, 2, 0))  # Transpose for visualization (if needed)
  plt.imshow(img)
  plt.show()

# Define the number of images to display (adjust as needed)
num_images = 1

# Loop through the desired number of images
for i in range(num_images):
  # Get a random image and label (assuming label is at index 1)
  img, label, extra_info = train_dataset[np.random.randint(0, len(train_dataset))]  # Random index

  # Display the image
  imshow(img)

"""##3. Fine-Tuning MobileNetV3 Model

##MobileNetV3
"""

# Load pre-trained GoogLeNet
mobilenet_v3_model = models.mobilenet_v3_small(pretrained=True)

# Freeze all layers for param in model.parameters()
for param in mobilenet_v3_model.parameters():
    param.requires_grad = False

"""#####Unfreezing the last three layers"""

# Unfreeze the last three layers of the features
for param in mobilenet_v3_model.features[-1].parameters():
    param.requires_grad = True
for param in mobilenet_v3_model.features[-2].parameters():
    param.requires_grad = True
for param in mobilenet_v3_model.features[-3].parameters():
    param.requires_grad = True

num_ftrs = 576

# Remove the original classifier and add custom layers
mobilenet_v3_model.classifier = nn.Sequential(
    nn.Linear(num_ftrs, 512),
    nn.ReLU(),
    nn.Dropout(0.3),
    nn.Linear(512, 256),
    nn.ReLU(),
    nn.Dropout(0.3),
    nn.Linear(256, 101)  # Assuming 101 classes in Food101 dataset
)

# Choose the device for training based on GPU availability: use GPU if available, else use CPU
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Define the loss function (Cross Entropy Loss) for the classification task
criterion = nn.CrossEntropyLoss()

new_learning_rate = 0.00005  #new learning rate
optimizer = optim.Adam(filter(lambda p: p.requires_grad, mobilenet_v3_model.parameters()), lr=new_learning_rate)

# Define a learning rate scheduler to adjust the learning rate during training based on validation loss
scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.2, patience=3, min_lr=0.0000001)

early_stop_counter = 0
early_stop_patience = 10
best_val_loss = float('inf')

# Define a function to check for early stopping
def check_early_stop(val_loss):
    global early_stop_counter, best_val_loss  # Access global variables for early stopping

    # Check if the current validation loss is better than the best validation loss seen so far
    if val_loss < best_val_loss:
        best_val_loss = val_loss  # Update the best validation loss
        early_stop_counter = 0  # Reset the early stopping counter
    else:
        early_stop_counter += 1  # Increment the early stopping counter

    # Check if the early stopping criterion (patience) has been met
    if early_stop_counter >= early_stop_patience:
        print("Early stopping triggered!")  # Print a message indicating early stopping
        return True  # Return True to indicate that early stopping is triggered
    else:
        return False  # Return False to indicate that early stopping is not triggered

mobilenet_v3_model.to(device)

# Initialize lists to store metrics
train_losses = []         # List to store training losses for each epoch
train_accuracies = []     # List to store training accuracies for each epoch
val_losses = []           # List to store validation losses for each epoch
val_accuracies = []       # List to store validation accuracies for each epoch

# Training loop
num_epochs = 15           # Number of epochs for training
for epoch in range(num_epochs):  # Iterate over each epoch
    mobilenet_v3_model.train()               # Set the model to train mode
    running_loss = 0.0          # Initialize running loss for this epoch
    correct_train = 0           # Initialize number of correct predictions for training
    total_train = 0             # Initialize total number of samples for training

    # Iterate over the training dataset
    for inputs, l,labels in tqdm(train_loader,total=len(train_loader)):

        inputs, labels = inputs.to(device), labels.to(device)  # Move inputs and labels to device

        optimizer.zero_grad()  # Zero the parameter gradients

        # Inside your training loop, just before passing inputs to the model
        #print(f"Input shape before model: {inputs.shape}")  # Debugging print

        #if len(inputs.shape) == 3:  # Assuming missing channel dimension for grayscale images
          #inputs = inputs.unsqueeze(1)  # Add channel dimension
          #print(f"Input shape after unsqueeze: {inputs.shape}")  # Confirm shape

        optimizer.zero_grad()  # Zero the parameter gradients
        outputs = mobilenet_v3_model(inputs) # Forward pass
        labels_one_hot = F.one_hot(labels.long(), num_classes=101).float()
        loss = criterion(outputs.squeeze(), labels_one_hot) # Compute the loss
        loss.backward() # Backward pass
        optimizer.step() # Weight updates
        running_loss += loss.item() # Count the total loss

        # Calculate training accuracy
        predicted = torch.round(outputs).squeeze()
        correct_train += (torch.argmax(predicted,dim=1) == labels).sum().item()
        total_train += labels.size(0)  # Count total samples

    train_loss = running_loss / len(train_loader)  # Calculate average training loss
    train_accuracy = correct_train / total_train  # Calculate training accuracy

    # Validation loop
    mobilenet_v3_model.eval()  # Set the model to evaluation mode
    val_running_loss = 0.0  # Initialize running loss for validation
    correct_val = 0  # Initialize number of correct predictions for validation
    total_val = 0  # Initialize total number of samples for validation

    # Disable gradient calculation for validation
    with torch.no_grad():
        for inputs,l, labels in tqdm(val_loader,total=len(val_loader)):
            inputs, labels = inputs.to(device), labels.to(device)  # Move inputs and labels to device
            outputs = mobilenet_v3_model(inputs)  # Forward pass
            labels_one_hot = F.one_hot(labels.long(), num_classes=101).float()
            loss = criterion(outputs.squeeze(), labels_one_hot) # Compute the validation loss
            val_running_loss += loss.item() # Accumulate the running loss
            # Calculate validation accuracy
            predicted = torch.round(outputs).squeeze()
            correct_val += (torch.argmax(predicted,dim=1) == labels).sum().item() # Compare between the predicted and actual
            total_val += labels.size(0)  # Count total samples

    # Calculate average validation loss and accuracy for the epoch
    val_loss = val_running_loss / len(val_loader)  # Calculate average validation loss
    val_accuracy = correct_val / total_val  # Calculate validation accuracy

    # Update the learning rate
    scheduler.step(val_loss)

    # Check for early stopping
    if check_early_stop(val_loss):
        break

    # Save metrics
    train_losses.append(train_loss)  # Append training loss
    train_accuracies.append(train_accuracy)  # Append training accuracy
    val_losses.append(val_loss)  # Append validation loss
    val_accuracies.append(val_accuracy)  # Append validation accuracy

    # Print epoch results
    print(f"Epoch [{epoch + 1}/{num_epochs}], \
          Training Loss: {train_loss:.4f}, \
          Training Accuracy: {train_accuracy:.2%}, \
          Validation Loss: {val_losses[-1]:.4f}, \
          Validation Accuracy: {val_accuracy:.2%}")  # Print epoch results

# Evaluation for test data
mobilenet_v3_model.eval()  # Set model to evaluation mode
test_correct = 0  # Initialize number of correctly predicted samples
test_total = 0  # Initialize total number of samples
test_running_loss = 0.0  # Initialize running test loss

with torch.no_grad():  # Turn off gradients during evaluation
    for inputs, l,labels in test_loader:  # Iterate through test data
        inputs, labels = inputs.to(device), labels.to(device)  # Move data to GPU
        outputs = mobilenet_v3_model(inputs)  # Get model predictions
        if isinstance(outputs, tuple):
            logits = outputs[0]  # Unpack logits from model outputs if necessary
        else:
            logits = outputs
        loss = criterion(logits, labels)  # Calculate loss

        test_running_loss += loss.item() * inputs.size(0)  # Update running test loss
        _, predicted = torch.max(logits, 1)  # Get predicted labels
        test_total += labels.size(0)  # Update total number of samples
        test_correct += (predicted == labels).sum().item()  # Update number of correctly predicted samples

# Calculate test loss and accuracy
test_loss = test_running_loss / len(test_loader.dataset)  # Average test loss
test_accuracy = test_correct / test_total  # Test accuracy

# Print test results
print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}')

#Training and validation Accuracies
import matplotlib.pyplot as plt

# Plot training and validation losses starting from index 1
epochs = range(1, len(train_losses) + 1)  # Generate the range of epochs starting from 1

# Plot training and validation accuracies
plt.plot(epochs, train_accuracies, label='Training Accuracy')  # Plot training accuracies over epochs
plt.plot(epochs, val_accuracies, label='Validation Accuracy')  # Plot validation accuracies over epochs
plt.xlabel('Epoch')  # Set label for the x-axis
plt.ylabel('Accuracy')  # Set label for the y-axis
plt.title('Training and Validation Accuracies')  # Set title for the plot
plt.legend()  # Display legend
plt.show()  # Show the plot

# Plot training and validation losses starting from index 1
epochs = range(1, len(train_losses) + 1)  # Generate the range of epochs starting from 1

# Plot training and validation losses
plt.plot(epochs, train_losses, label='Training Loss')  # Plot training losses over epochs
plt.plot(epochs, val_losses, label='Validation Loss')  # Plot validation losses over epochs
plt.xlabel('Epoch')  # Set label for the x-axis
plt.ylabel('Loss')  # Set label for the y-axis
plt.title('Training and Validation Losses')  # Set title for the plot
plt.legend()  # Display legend
plt.grid(True)  # Display grid
plt.show()  # Show the plot





